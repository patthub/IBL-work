{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "functions",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUbnkoYUmsZZ"
      },
      "outputs": [],
      "source": [
        "def open_data(path):\n",
        "    with open (path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "def get_data(url: str) -> list:\n",
        "    responses = []\n",
        "    while url:\n",
        "        url = requests.get(url)\n",
        "        if url.status_code == 200:\n",
        "            url = url.json()\n",
        "            responses.append(url)\n",
        "            url = url[\"nextPage\"]\n",
        "            print(f\"Downloading: {url}\")\n",
        "        else:\n",
        "            print(\"Error while accessing API\")\n",
        "    print(\"Download complete\")\n",
        "    return responses\n",
        "    \n",
        "         \n",
        " \n",
        "        \n",
        "def get_subj(sub: str, header: str, field_numbers: list) -> dict:  \n",
        "    responses = get_data(f\"http://data.bn.org.pl/api/authorities.json?{header}={sub}\")\n",
        "    subjects = []\n",
        "    for response in responses:\n",
        "        for authority in response[\"authorities\"]:\n",
        "            for field in authority[\"marc\"][\"fields\"]:\n",
        "                for field_number in field_numbers:\n",
        "                    if field_number in field:\n",
        "                        for i in field:\n",
        "                            subjects.append(list(field[i][\"subfields\"][-1].values())[0])\n",
        "                \n",
        "    subjects_dict = {}\n",
        "    subjects_dict[sub] = subjects\n",
        "    return subjects_dict\n",
        "\n",
        "\n",
        "def prepare_fbc_subjects(path: str) -> list:\n",
        "    SUBJECTS_ALL = pd.read_csv(path)\n",
        "    subjects_fbc = SUBJECTS_ALL[\"0\"].values.tolist()\n",
        "    return [x for x in list(set(subjects_fbc)) if str(x) !=\"nan\"]\n",
        "    \n",
        "\n",
        "# def subject_matcher(path: str, subjects: dict,) -> list:\n",
        "    \n",
        "#     subjects_fbc = prepare_fbc_subjects(path)\n",
        "#     subjects_fbc_with_dbn = [x.replace(\"DBN\", \"\").strip() for x in subjects_fbc]  \n",
        "#     subjects_dbn = []\n",
        "#     for subject in list(subjects.values())[0]:\n",
        "#         subjects_dbn.append(subject)\n",
        "#     return [x for x in tqdm(subjects_fbc_with_dbn) if x in subjects_dbn]\n",
        "\n",
        "\n",
        "def subject_matcher(path: str, subjects: dict) -> list:\n",
        "    \n",
        "    subjects_fbc = prepare_fbc_subjects(path)\n",
        "    subjects_fbc_with_dbn = [x.replace(\"DBN\", \"\").strip() for x in subjects_fbc]\n",
        "    subjects_dbn = []\n",
        "    for subject in list(subjects.values())[0]:\n",
        "        subjects_dbn.append(subject)\n",
        "    return [x for x in tqdm(subjects_fbc_with_dbn) if x in subjects_dbn]\n",
        "\n",
        "def lemmatize(term):\n",
        "    lemmas = \" \".join([w.lemma_ for w in nlp(term)])\n",
        "    return lemmas\n",
        "\n",
        "def get_fields_of_subj(subjects: list, fields: list) -> list:\n",
        "    list_of_dicts = []\n",
        "    for subject in subjects:\n",
        "        subjects_with_fields = get_subj(subject, \"subject\", fields)\n",
        "        list_of_dicts.append(subjects_with_fields)\n",
        "    return list_of_dicts\n",
        "    "
      ]
    }
  ]
}